# ðŸ”’ Configuration des Logs de SÃ©curitÃ© depuis Clients Distants

## ðŸ“‹ Vue d'ensemble

Ce guide explique comment configurer un client Ubuntu distant pour envoyer ses logs de sÃ©curitÃ© (authentification SSH, syslog, fail2ban, dÃ©tection d'intrusion) vers votre instance ElasticDocker Kibana.

### âœ¨ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client Ubuntu Distant      â”‚
â”‚  (192.168.2.101 ou autre)   â”‚
â”‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Filebeat 9.2.3      â”‚   â”‚â”€â”€â”
â”‚  â”‚ /var/log/auth.log   â”‚   â”‚  â”‚
â”‚  â”‚ /var/log/syslog     â”‚   â”‚  â”‚
â”‚  â”‚ /var/log/fail2ban   â”‚   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                 â”‚ Port 5044
                                 â”‚ (Beats Protocol)
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Serveur ElasticDocker (192.168.2.102)                      â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Logstash    â”‚â”€â”€â”€â–¶â”‚ Elasticsearch â”‚â”€â”€â”€â–¶â”‚   Kibana     â”‚ â”‚
â”‚  â”‚  Port 5044   â”‚    â”‚  Port 9200    â”‚    â”‚  Port 5601   â”‚ â”‚
â”‚  â”‚  Pipeline    â”‚    â”‚  Index:       â”‚    â”‚  Dashboard   â”‚ â”‚
â”‚  â”‚  security-   â”‚    â”‚  security-    â”‚    â”‚  Visualize   â”‚ â”‚
â”‚  â”‚  logs.conf   â”‚    â”‚  logs-*       â”‚    â”‚              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸŽ¯ Objectifs

- âœ… Centraliser les logs de sÃ©curitÃ© de tous vos serveurs Ubuntu
- âœ… DÃ©tecter les tentatives d'intrusion SSH (Ã©checs, utilisateurs invalides)
- âœ… Monitorer les actions fail2ban (bannissements IP)
- âœ… Analyser les Ã©vÃ©nements systÃ¨me critiques
- âœ… GÃ©olocaliser les IP sources des attaques
- âœ… Visualiser dans Kibana avec dashboards

---

## ðŸ–¥ï¸ Configuration Serveur (192.168.2.102)

### âœ… Ã‰tape 1 : VÃ©rifier la configuration Logstash (DÃ©jÃ  fait)

Les fichiers suivants sont dÃ©jÃ  configurÃ©s dans votre ElasticDocker :

#### **1. Pipeline security-logs.conf**
- **Emplacement** : `logstash/pipeline/security-logs.conf`
- **Fonction** : Parse les logs auth.log, syslog, fail2ban
- **FonctionnalitÃ©s** :
  - DÃ©tection SSH : failed password, successful auth, invalid user
  - Enrichissement GeoIP pour localiser les attaquants
  - Classification par sÃ©vÃ©ritÃ© : high, medium, info
  - Index Elasticsearch : `security-logs-YYYY.MM.dd`

#### **2. Configuration pipelines.yml**
- **Emplacement** : `logstash/config/pipelines.yml`
- **Ligne ajoutÃ©e** :
```yaml
- pipeline.id: security-logs
  path.config: "/usr/share/logstash/pipeline/security-logs.conf"
  queue.type: persisted
  pipeline.batch.size: 200
  pipeline.workers: 2
```

#### **3. Beats Input configurÃ©**
- **Port** : 5044
- **Host** : 0.0.0.0 (Ã©coute toutes interfaces)
- **Protocole** : Beats (Filebeat, Metricbeat, etc.)

### âœ… Ã‰tape 2 : Configurer le firewall (Si nÃ©cessaire)

Votre firewall est actuellement **inactif** (`ufw status: inactive`). Si vous l'activez ou utilisez `iptables`, ouvrez le port 5044 :

#### **Avec UFW :**
```bash
# Autoriser Beats depuis votre rÃ©seau local
sudo ufw allow from 192.168.2.0/24 to any port 5044 proto tcp comment 'Logstash Beats Input'

# Ou depuis une IP spÃ©cifique
sudo ufw allow from 192.168.2.101 to any port 5044 proto tcp

# VÃ©rifier
sudo ufw status numbered
```

#### **Avec iptables :**
```bash
# Autoriser depuis le rÃ©seau local
sudo iptables -A INPUT -p tcp -s 192.168.2.0/24 --dport 5044 -j ACCEPT -m comment --comment "Logstash Beats"

# Sauvegarder les rÃ¨gles
sudo netfilter-persistent save
```

#### **VÃ©rifier le port ouvert :**
```bash
# VÃ©rifier que Logstash Ã©coute sur 5044
sudo ss -tulpn | grep 5044

# Devrait afficher :
# tcp   LISTEN 0   128   0.0.0.0:5044   0.0.0.0:*   users:(("java",pid=XXXX))
```

### âœ… Ã‰tape 3 : RedÃ©marrer Logstash avec le nouveau pipeline

```bash
# Depuis le rÃ©pertoire elastdocker/
cd /home/admsrv/elastdocker

# RedÃ©marrer Logstash uniquement
docker compose restart logstash

# VÃ©rifier les logs
docker logs elastic-logstash-1 --tail 50

# Attendre le message :
# "Successfully started Logstash API endpoint {:port=>9600, :ssl_enabled=>false}"
# "Pipeline started {\"pipeline.id\"=>\"security-logs\"}"
```

### âœ… Ã‰tape 4 : VÃ©rifier que le pipeline est chargÃ©

```bash
# API Logstash pour voir les pipelines actifs
curl -s http://localhost:9600/_node/stats/pipelines?pretty | grep -A 5 "security-logs"

# Devrait afficher :
# "security-logs" : {
#   "events" : {
#     "in" : 0,
#     "filtered" : 0,
#     "out" : 0
```

---

## ðŸ’» Configuration Client Ubuntu Distant

### Ã‰tape 1 : Installation de Filebeat 9.2.3

**Sur le client Ubuntu distant** (exemple : 192.168.2.101), exÃ©cutez :

```bash
# 1. Ajouter la clÃ© GPG Elastic
wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg

# 2. Ajouter le repository Elastic 9.x
echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/9.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-9.x.list

# 3. Installer Filebeat
sudo apt-get update
sudo apt-get install filebeat=9.2.3

# 4. VÃ©rifier la version
filebeat version
# Devrait afficher : filebeat version 9.2.3
```

### Ã‰tape 2 : Copier la configuration Filebeat

Le fichier `filebeat-client-config.yml` est prÃªt dans votre repository ElasticDocker.

**Sur le serveur (192.168.2.102)** :
```bash
# Afficher la configuration
cat /home/admsrv/elastdocker/filebeat-client-config.yml
```

**Sur le client (192.168.2.101)** :

**Option A : Copie via SCP** (depuis le serveur vers le client) :
```bash
# Depuis le serveur
scp /home/admsrv/elastdocker/filebeat-client-config.yml user@192.168.2.101:/tmp/

# Sur le client
sudo cp /tmp/filebeat-client-config.yml /etc/filebeat/filebeat.yml
```

**Option B : Copie manuelle** :
```bash
# Sur le client
sudo nano /etc/filebeat/filebeat.yml
# Coller le contenu du fichier filebeat-client-config.yml
```

**Option C : TÃ©lÃ©chargement direct si disponible** :
```bash
# Si vous avez mis le fichier sur un serveur web
curl -o /tmp/filebeat.yml https://votre-serveur/filebeat-client-config.yml
sudo cp /tmp/filebeat.yml /etc/filebeat/filebeat.yml
```

### Ã‰tape 3 : VÃ©rifier les permissions des fichiers logs

Filebeat doit pouvoir lire les fichiers de logs :

```bash
# VÃ©rifier les permissions
ls -l /var/log/auth.log /var/log/syslog /var/log/kern.log

# Si Filebeat ne peut pas lire, ajouter l'utilisateur filebeat au groupe adm
sudo usermod -a -G adm filebeat

# Ou ajuster les permissions (moins recommandÃ©)
sudo chmod 644 /var/log/auth.log /var/log/syslog
```

### Ã‰tape 4 : Tester la configuration Filebeat

```bash
# Tester la configuration (ne dÃ©marre pas Filebeat)
sudo filebeat test config -c /etc/filebeat/filebeat.yml

# Devrait afficher :
# Config OK

# Tester la connexion vers Logstash
sudo filebeat test output -c /etc/filebeat/filebeat.yml

# Devrait afficher :
# logstash: 192.168.2.102:5044...
#   connection...
#     parse host... OK
#     dns lookup... OK
#     addresses: 192.168.2.102
#     dial up... OK
#   TLS... WARN secure connection disabled
#   talk to server... OK
```

### Ã‰tape 5 : DÃ©marrer Filebeat

```bash
# Activer au dÃ©marrage
sudo systemctl enable filebeat

# DÃ©marrer le service
sudo systemctl start filebeat

# VÃ©rifier le statut
sudo systemctl status filebeat

# Devrait afficher :
# â— filebeat.service - Filebeat sends log files to Logstash or directly to Elasticsearch.
#    Loaded: loaded (/lib/systemd/system/filebeat.service; enabled; vendor preset: enabled)
#    Active: active (running) since ...
```

### Ã‰tape 6 : VÃ©rifier les logs Filebeat

```bash
# Voir les logs du service
sudo journalctl -u filebeat -f --since "5 minutes ago"

# Ou voir le fichier de log
sudo tail -f /var/log/filebeat/filebeat

# Messages attendus :
# "Connection to backoff(async(tcp://192.168.2.102:5044)) established"
# "Non-zero metrics in the last 30s" (indique que des Ã©vÃ©nements sont envoyÃ©s)
```

---

## ðŸ§ª Tests et Validation

### Test 1 : GÃ©nÃ©rer des Ã©vÃ©nements de test sur le client

```bash
# Test SSH failed authentication (depuis un autre terminal)
ssh utilisateur_inexistant@localhost

# Test sudo (gÃ©nÃ¨re un Ã©vÃ©nement auth.log)
sudo ls /root

# VÃ©rifier que les logs sont gÃ©nÃ©rÃ©s
sudo tail /var/log/auth.log
```

### Test 2 : VÃ©rifier rÃ©ception dans Logstash (serveur)

```bash
# Voir les logs Logstash en temps rÃ©el
docker logs elastic-logstash-1 -f

# Chercher des messages comme :
# "Beats input: client connected" {"ip"=>"192.168.2.101"}
```

### Test 3 : VÃ©rifier l'index Elasticsearch (serveur)

```bash
# Lister les indices security-logs
curl -k -u elastic:t9U6nXEme6nJ0IbM1bG2D2uq2ToWnx5Hh3EQSaZxUrU= \
  https://localhost:9200/_cat/indices/security-logs-*?v

# Devrait afficher un index comme :
# health status index                   docs.count
# yellow open   security-logs-2026.01.29  15

# RequÃªter les derniers Ã©vÃ©nements
curl -k -u elastic:t9U6nXEme6nJ0IbM1bG2D2uq2ToWnx5Hh3EQSaZxUrU= \
  "https://localhost:9200/security-logs-*/_search?pretty&size=5&sort=@timestamp:desc"
```

### Test 4 : Visualiser dans Kibana

1. **Ouvrir Kibana** :
   - URL : https://kibana.elastic.local (avec Traefik)
   - Ou : https://192.168.2.102:5601 (direct)
   - Login : `elastic` / `t9U6nXEme6nJ0IbM1bG2D2uq2ToWnx5Hh3EQSaZxUrU=`

2. **CrÃ©er un Data View** :
   - Menu â†’ Stack Management â†’ Data Views
   - Cliquer "Create data view"
   - Name : `Security Logs`
   - Index pattern : `security-logs-*`
   - Timestamp field : `@timestamp`
   - Cliquer "Save data view to Kibana"

3. **Explorer les donnÃ©es** :
   - Menu â†’ Discover
   - SÃ©lectionner "Security Logs" data view
   - Voir les logs SSH, syslog, etc.

4. **Filtres utiles** :
   ```
   tags: "ssh_failed_auth"          # Tentatives SSH Ã©chouÃ©es
   tags: "threat"                    # Tous Ã©vÃ©nements menaÃ§ants
   ssh_source_ip: "1.2.3.4"         # Depuis une IP spÃ©cifique
   security_severity: "high"         # SÃ©vÃ©ritÃ© haute uniquement
   ```

---

## ðŸ“Š Dashboards Kibana RecommandÃ©s

### Dashboard 1 : Security Overview

**Visualisations Ã  crÃ©er** :

1. **Metric : Total Failed SSH Attempts (Last 24h)**
   - Query : `tags: "ssh_failed_auth"`
   - Aggregation : Count

2. **Line Chart : SSH Events Over Time**
   - X-axis : @timestamp (histogram)
   - Y-axis : Count
   - Split by : tags (ssh_failed_auth vs ssh_successful_auth)

3. **Pie Chart : Top 10 Attacker IPs**
   - Query : `tags: "threat"`
   - Aggregation : Terms on `ssh_source_ip.keyword`

4. **Map : Geographic Location of Attacks**
   - Layer : Documents
   - Geospatial field : `geoip.location`
   - Query : `tags: "threat"`

5. **Data Table : Recent Failed Attempts**
   - Columns : @timestamp, ssh_user, ssh_source_ip, geoip.country_name
   - Query : `tags: "ssh_failed_auth"`
   - Sort : @timestamp desc
   - Size : 10

### Dashboard 2 : Fail2ban Actions

1. **Metric : Total Bans (Last 24h)**
   - Query : `tags: "fail2ban_action"`

2. **Data Table : Banned IPs**
   - Columns : fail2ban_timestamp, banned_ip, fail2ban_action, geoip.country_name

---

## ðŸ”’ SÃ©curisation (Production)

### 1. Activer SSL/TLS pour Beats â†’ Logstash

**Sur le serveur**, modifier `logstash/pipeline/security-logs.conf` :

```ruby
input {
    beats {
        port => 5044
        host => "0.0.0.0"

        # Activer SSL/TLS
        ssl => true
        ssl_certificate => "/certs/logstash/logstash.crt"
        ssl_key => "/certs/logstash/logstash.key"
        ssl_certificate_authorities => ["/certs/ca/ca.crt"]
        ssl_verify_mode => "force_peer"  # Valide le certificat client
    }
}
```

**Sur le client**, modifier `/etc/filebeat/filebeat.yml` :

```yaml
output.logstash:
  hosts: ["192.168.2.102:5044"]

  # Activer SSL/TLS
  ssl.enabled: true
  ssl.certificate_authorities: ["/etc/filebeat/certs/ca.crt"]
  ssl.certificate: "/etc/filebeat/certs/client.crt"
  ssl.key: "/etc/filebeat/certs/client.key"
```

### 2. Restreindre l'accÃ¨s rÃ©seau

```bash
# Firewall : autoriser UNIQUEMENT les IPs de vos clients
sudo ufw delete allow 5044
sudo ufw allow from 192.168.2.101 to any port 5044 proto tcp
sudo ufw allow from 192.168.2.105 to any port 5044 proto tcp
# ... rÃ©pÃ©ter pour chaque client
```

### 3. Rotation des logs Filebeat

Sur le client, configurer logrotate pour `/var/log/filebeat/filebeat` :

```bash
sudo nano /etc/logrotate.d/filebeat
```

Contenu :
```
/var/log/filebeat/filebeat {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
}
```

---

## ðŸ› DÃ©pannage

### ProblÃ¨me 1 : Filebeat ne peut pas se connecter Ã  Logstash

**SymptÃ´mes** :
```
Failed to connect to backoff(async(tcp://192.168.2.102:5044)): dial tcp: connect: connection refused
```

**Solutions** :
```bash
# 1. VÃ©rifier que Logstash Ã©coute sur le serveur
sudo ss -tulpn | grep 5044

# 2. Tester la connectivitÃ© rÃ©seau depuis le client
telnet 192.168.2.102 5044
# Ou
nc -zv 192.168.2.102 5044

# 3. VÃ©rifier le firewall sur le serveur
sudo ufw status
sudo iptables -L -n | grep 5044

# 4. VÃ©rifier les logs Logstash
docker logs elastic-logstash-1 | grep -i "beats"
```

### ProblÃ¨me 2 : Filebeat dÃ©marre mais n'envoie rien

**SymptÃ´mes** :
```
Non-zero metrics in the last 30s: 0 events sent
```

**Solutions** :
```bash
# 1. VÃ©rifier que les fichiers sont lisibles
sudo -u filebeat cat /var/log/auth.log

# 2. VÃ©rifier la configuration Filebeat
sudo filebeat test config -c /etc/filebeat/filebeat.yml

# 3. Activer le mode debug
sudo filebeat -e -d "*" -c /etc/filebeat/filebeat.yml

# 4. VÃ©rifier le registry Filebeat (Ã©tat de lecture des fichiers)
sudo cat /var/lib/filebeat/registry/filebeat/log.json | jq

# 5. Forcer la lecture depuis le dÃ©but (ATTENTION : envoie tous les logs historiques)
sudo systemctl stop filebeat
sudo rm -rf /var/lib/filebeat/registry
sudo systemctl start filebeat
```

### ProblÃ¨me 3 : Logs arrivent mais ne sont pas parsÃ©s

**SymptÃ´mes** : Champs `ssh_user`, `ssh_source_ip` absents dans Elasticsearch

**Solutions** :
```bash
# 1. VÃ©rifier le pipeline Logstash
docker logs elastic-logstash-1 | grep -i "grok"

# 2. Tester le grok pattern manuellement
# Aller sur : https://grokdebug.herokuapp.com/
# Pattern : %{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}
# Sample : Jan 29 14:23:45 ubuntu-client sshd[1234]: Failed password for invalid user test from 1.2.3.4 port 12345 ssh2

# 3. VÃ©rifier les tags sur les Ã©vÃ©nements
# Dans Kibana Discover, filtrer par : tags: "*"
```

### ProblÃ¨me 4 : Index non crÃ©Ã© dans Elasticsearch

**SymptÃ´mes** : `curl` ne trouve pas `security-logs-*`

**Solutions** :
```bash
# 1. VÃ©rifier que Logstash envoie vers Elasticsearch
docker logs elastic-logstash-1 | grep -i "elasticsearch"

# 2. VÃ©rifier manuellement les indices
curl -k -u elastic:PASSWORD https://localhost:9200/_cat/indices?v

# 3. VÃ©rifier la configuration output dans security-logs.conf
docker exec elastic-logstash-1 cat /usr/share/logstash/pipeline/security-logs.conf | grep -A 10 "output"

# 4. Tester la connexion Logstash â†’ Elasticsearch
docker exec elastic-logstash-1 curl -k -u elastic:PASSWORD https://elasticsearch:9200/_cluster/health
```

### ProblÃ¨me 5 : GeoIP ne fonctionne pas

**SymptÃ´mes** : Champ `geoip` absent ou vide

**Solutions** :
```bash
# 1. VÃ©rifier que le module GeoIP est prÃ©sent dans Logstash
docker exec elastic-logstash-1 ls -la /usr/share/logstash/vendor/bundle/jruby/*/gems/ | grep geoip

# 2. TÃ©lÃ©charger la base GeoIP manuellement si nÃ©cessaire
# (Normalement incluse dans l'image Logstash 9.2.3)

# 3. VÃ©rifier les logs d'erreur GeoIP
docker logs elastic-logstash-1 | grep -i geoip
```

---

## ðŸ“ Checklist de dÃ©ploiement

### Serveur (192.168.2.102)

- [x] Pipeline `security-logs.conf` crÃ©Ã©
- [x] Pipeline ajoutÃ© Ã  `pipelines.yml`
- [ ] Logstash redÃ©marrÃ© avec `docker compose restart logstash`
- [ ] Pipeline `security-logs` actif (vÃ©rifier avec API)
- [ ] Port 5044 ouvert dans le firewall (si activÃ©)
- [ ] Port 5044 accessible depuis le rÃ©seau (test `nc -zv`)

### Client Ubuntu (192.168.2.101 ou autre)

- [ ] Filebeat 9.2.3 installÃ© (`filebeat version`)
- [ ] Configuration `filebeat.yml` copiÃ©e et adaptÃ©e
- [ ] IP serveur correcte : `192.168.2.102:5044`
- [ ] Permissions lectures logs OK (`sudo -u filebeat cat /var/log/auth.log`)
- [ ] Test configuration : `filebeat test config` â†’ OK
- [ ] Test connexion : `filebeat test output` â†’ OK
- [ ] Filebeat dÃ©marrÃ© : `systemctl status filebeat` â†’ active (running)
- [ ] Logs Filebeat : connexion Ã©tablie

### Validation End-to-End

- [ ] Index `security-logs-*` crÃ©Ã© dans Elasticsearch
- [ ] Ã‰vÃ©nements visibles avec `curl` ou Kibana Discover
- [ ] Champs parsÃ©s : `ssh_user`, `ssh_source_ip`, `geoip`, `security_severity`
- [ ] Data View crÃ©Ã© dans Kibana
- [ ] Dashboard ou visualisation fonctionnel

---

## ðŸ”§ Maintenance

### Monitoring rÃ©gulier

```bash
# Sur le serveur : vÃ©rifier le dÃ©bit d'Ã©vÃ©nements
curl -s http://localhost:9600/_node/stats/pipelines | jq '.pipelines."security-logs".events'

# VÃ©rifier la taille des indices
curl -k -u elastic:PASSWORD https://localhost:9200/_cat/indices/security-logs-*?v&h=index,docs.count,store.size

# Sur le client : vÃ©rifier l'envoi Filebeat
sudo filebeat export ilm-policy
sudo journalctl -u filebeat | tail -20
```

### ILM (Index Lifecycle Management)

Configurer la rÃ©tention automatique pour Ã©viter de saturer le disque :

```bash
# CrÃ©er une politique ILM : garder 30 jours, puis supprimer
curl -k -u elastic:PASSWORD -X PUT "https://localhost:9200/_ilm/policy/security-logs-policy" \
-H 'Content-Type: application/json' -d'
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "50GB",
            "max_age": "1d"
          }
        }
      },
      "delete": {
        "min_age": "30d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
'

# Appliquer la politique Ã  l'index pattern
# (DÃ©jÃ  configurÃ© dans security-logs.conf avec ilm_enabled => auto)
```

---

## ðŸ“š Ressources

- **Elastic Beats** : https://www.elastic.co/guide/en/beats/filebeat/9.2/index.html
- **Logstash Grok Patterns** : https://github.com/logstash-plugins/logstash-patterns-core/tree/main/patterns
- **GeoIP Filter** : https://www.elastic.co/guide/en/logstash/9.2/plugins-filters-geoip.html
- **Kibana Visualizations** : https://www.elastic.co/guide/en/kibana/9.2/dashboard.html

---

**GÃ©nÃ©rÃ© le** : 2026-01-29
**Version** : Elasticsearch 9.2.3

ðŸ¤– **Generated with [Claude Code](https://claude.com/claude-code)**

Co-Authored-By: Claude <noreply@anthropic.com>
